# 概述

## 几个产品

Apache Lucene是一个开源的分布式包

Apache Solr是基于Lucene的一个开源的分布式搜索引擎：2004年发布

Elasticsearch也是基于Lucene的一个开源的分布式搜索引擎：2010年发布

Apache Lucene和Solr在2010年时已经合并为一个Apache项目

## ES能做什么

### 功能

- 基本的搜索功能
  - 倒排索引
  - 根据词频得到的结果相关性
- 额外功能
  - 处理拼写错误
  - 支持近义词
  - 支持统计信息
  - 可给与自动提示

### 场景

- 直接当后端的数据库，存储和查询都在ES中做
- 只当搜索引擎，存储在数据库中，搜索在ES中，ES中存储数据的索引，有一个数据同步问题。

## ES基本原理

### 核心概念（ES的逻辑设计）

- 文档

  和一般NoSQL数据库中的文档概念一致，用于存储某条记录。一个文档是一个JSON对象，具有层次结构，且层次结构灵活固定（没有预先定义好的schema）

  ES的最小单位是文档，因此更新和搜索的目标都是文档

  文档使用文档ID标识

  文档类比关系数据库中的行。

- 类型

  类型是文档的容器，即用来盛装一系列文档。在逻辑上，一个文档属于一个类型。

  尽管文档本身没有schema限制，但是在同一个类型中最好放入相同schema的文档。

  一定程度上，类型可以理解为相同schema的文档的集合

  类型类比关系数据库中的表格。

  - 子概念——映射

    类型中字段的定义称为映射。例如name字段映射为string

- 索引

  索引是类型的容器，是独立的大量文档的集合。
  
  索引类比关系数据库的database

每篇文章属于一种类型，每种类型属于一个索引。

索引-类型-文档ID唯一确定了ES中的某篇文档。在搜索时，可以查找特定索引、特定类型中的文档。也可以跨多个类型甚至索引进行搜索。

### 如何做到分布式

- 分片

  ES默认分片，每个分片还有一个副本分片用于保证可用性。数据库的复制和扩展都是以分片为最小单位。这和Redis的虚拟槽相似（将所有数据映射到多个槽，在集群节点扩展和减少时只需要迁移槽即可）

  一份分片就是一个Lucene索引

  同一个ES索引中的索引文档，无论何种类型，都存储在相同分片的同一组文件中。因此，**类型的概念仅是ES上的抽象，并不属于Lucene**

  由于类型概念是ES提供的，因此ES是首先从lucene索引中获取符合要求的文档，再自己根据类型过滤一遍。

- 节点

  真实的物理机器。

### 如何索引和搜索

- 索引

  索引一个文档时，通过hash算法决定将文档索引到哪个分片上，在该分片和其副分片都索引完成后，索引命令返回成功。

  索引并非实时的，即刚添加的索引是不能马上就查询到的，需要等刷新到磁盘并打开对应的segment才能查到。默认刷新时间是1秒。

- 搜索

  通过round-robin轮询的方法，轮询可用的分片，并将搜索请求转发过去，所有分片响应后再集合搜索结果，返回给用户。

## 第三章 索引、更新和删除数据

词条(term)是文本中的一个单词，是搜索的基本单位。

可以设置某个字段的index属性为no，这样该字段就不会被索引，也就没有词条产生，因此无法在哪个字段上进行搜索。

### ES的类型

#### 核心类型

- 字符串类型
- 数值类型：byte、short、int、long、float、double
- 日期类型：其原理是，索引或搜索时，提供ISO8601格式的日期字符串，ES会将其转换为epoch值存入Lucene。

> 小贴士：ISO 8601的完整格式是这样的：2010-10-10T10:22:12.222+08:00 带毫秒数和时区。但其中的大多数信息是可选的。比如可省略毫秒、省略整个时间部分、省略时区等。

- 布尔类型：Lucene中布尔类型被存储成了T和F

#### 数组和多字段

- 数组：将一个字段进行分词后，得到的就是个数组。因此其实所有字段都支持数组的，他们被和单个词一样处理，在拆分倒排后都是一样的。
- 多字段：即对同一个字段索引多次。

#### 预定义字段

以下划线开始就是预定义字段，这些字段用于为文档添加新的元数据。

认识几个重要的预定义字段

- _source：按照原有格式存储原本的文档，即索引之前的文档。从2.0版本开始就无法再关闭该选项了。
- \_all：索引所有的信息。当不指定搜索的字段时，将会从文档索引的所有信息中搜索，即只会匹配`_all`所包含的字段
- \_uid：用户唯一标识整个索引中的某篇文档

### 文档的更新

支持普通更新、upsert、increase等

#### 并发控制

更新的并发控制使用的是基于版本号的乐观锁。

### 文档的删除

- 删除单个或多个文档：ES并没有马上删除，而是将其标记为删除，搜索时将其滤除。真正的删除是之后异步完成的
- 删除整个索引：会移除和该索引相关的所有文件，马上就会被执行。
- 关闭索引：索引依旧在磁盘上，只是不会被加载到内存中而已。

## 第四章 搜索数据

ES的查询功能很强大。

## 第五章 分析数据

即在文档加入倒排索引之前，对文档相关字段做的一系列处理

- 字符过滤：使用字符过滤器转变字符，如将&转换为and
- 分词：将文本切分为多个单词
- 分词过滤：使用分词过滤器转变每个分词。如转换为消息，增加同义词等。
- 分词索引：将分词添加到索引

### 分析器

一个分析器包含一个可选的字符过滤器、一个分词器、多个分词过滤器

ES有很多内置的分析器。也有很多内置的过滤器、分词器、分词过滤器可供选择，可以自定义组合完成强大的功能。

### N元语法、侧边N元语法和华东窗口

N元语法，就是将一个单词切割成多个子单词

如2元语法过滤器，将hello切分成he、el、ll、lo四个单词

侧边2元语法，将hello切分成he

滑动窗口，设置为2，何以分成he、el、ll、lo四个单词

### 词干提取

即将单词缩写到基本或词根的形式。如可以将administrations提取为administr，这样搜索administrator时也可以匹配到。

可以通过算法或字典提取词干。使用字典更准确。

## 第六章 ES的打分机制

第一流行的方式：TF-IDF：term frequency - inverse document frequency ，即词频-逆文档频率

第二流行的方式：OKapi BM25

### boosting

是用来修改文档相关性的程序。可以在查询或索引时使用，用来提升一篇文章的得分。

如果在索引时使用，boosting存储在索引中，修改boosting唯一的方式就冲重新索引整个索引。

如果在查询时就方便很多。

boosting的使用场景：查询文章时，title字段的打分比重应该大于content的打分比重。

## 第七章 使用聚集

聚集有两个主要类别

- 度量型(metrics)：指一组文档的统计分析，得到注入最大、最小、标准差等
- 桶型(bucket)：将匹配的文档切分为多个容器，在每个容器中再嵌套聚集。例如统计每个季度销售额的平均值。

### ES提供的近似统计

- 百分位：即percentiles，和metrics中的一样。即百分之多少的结果是再该数值之下
- 基数：cardinality，使用HyperLogLog++算法。

### ES的桶聚集

- 词条聚集
- 范围聚集
- 直方图聚集
- 嵌套聚集
- 地理距离聚集

## 第八章 文档之间的关联

本章跳过

## 第九章 向外扩展

### 发现其它ES节点

ES使用两种方式来发现其它节点：广播和单播。

默认只是用广播。ES启动时，向224.2.2.4:54328发送广播ping。其它节点响应这个请求。

单播推荐在线上使用，需要手动配置一系列主机地址。防止广播后自动加入集群。

集群节点发现彼此后，会选举出主节点，负责管理集群的状态。主节点还会建立内部的ping机制确保每个节点的活跃和健康。

### 删除节点

在有副本的情况下，一个节点挂了并不会对数据造成影响。但如果挂掉的节点超过副本数量，则可能出现某个分片的数据丢失的情况。

运维ES的一个重要任务就是，确定性能和自己能够承受的风险的平衡点。副本越多越安全，但索引效率越慢；副本越少越不安全，但索引速度会变快。

### 停用节点

当某台机器过于老旧，需要移除时，可以使用软停用，告诉节点不要再分配副本在本机上了。从而实现节点优雅地移除。

### 升级节点

可以关闭自动分配设置，升级完成后再打开，以免副本被重新分配。

### 别名

别名就是对索引起一个名字，在使用时使用该别名和索引效果一样。起到了解耦的作用。之后可以无缝替换实际的索引。

### 路由

我们知道一个索引有多个分片，路由就是决定你的文档要存到哪个分片的过程。

默认情况下，ES确保你的文档以均衡的方式分布在所有分片中。

什么情况下需要自定义路由呢？——作为一种文档隔离策略。即我已经知道文档分为多类，比如一些文档属于一个城市，另一些属于另一个城市。我可以将他们根据城市路由，将同一个城市的文档路由到一个分片中，这样查询该城市的数据时总是在一个分片中查询。能够提升查询速度。

## 第十章 提升性能

该章节主要讲了ES索引的底层原理，可以参见下面的面试题。

手册：https://www.elastic.co/guide/cn/elasticsearch/guide/current/index.html

# Elasticsearch面试题

## ES进行master选举原理



## ES写入数据的原理

- 客户端向ES集群发起写入索引请求，由集群中的一个节点复杂执行此次索引的协调
- 协调节点对新写入的document进行路由，确认将该document写入到哪个分片？并将该document转发到目标分片的节点。
- 目标分片节点向分片写入数据，并将数据同步到对应的副本分片。
- 在主分片和副本分片都写入完成后，则写入成功，响应给客户端。

![img](https://img-blog.csdnimg.cn/20190404080453917.JPG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2FiY2QxMTAx,size_16,color_FFFFFF,t_70)

## ES获取数据的原理

通过doc id读取数据的原理。

- 客户端向集群发起读取请求，挑选一个ES节点成为协调节点
- 协调节点对doc id进行hash路由，定位到某个ID的分片，再通过round-robin算法从主分片和众多副本分片中挑选分片（分片间负载均衡），得到具体分片，将请求转发到该分片的节点
- 具体节点读取数据，返回协调节点
- 协调节点读取数据返回给客户端

通过search搜索数据的原理（query-fetch）

搜索的层级可以有很多：在所有索引中搜索、在指定索引中搜索、在指定索引中的指定字段中搜索等。以在指定索引中搜索距离

- 客户端连接上ES协调节点
- 协调节点将搜索的条件转发到所有该索引分片存在的节点
- 各节点根据搜索条件进行搜索（搜索其实是在分片内部进行的），将搜索结果返回给协调节点，由协调节点进行合并、排序、分页等操作，得到一批数据的doc id
- 协调节点再拿着这些doc id拉取完整的数据。
- 将数据返回给客户端。

### 任何节点都能成为协调节点吗？



## 索引（写入数据）的底层原理

ES的搜索操作是近实时的，这意味着刚刚写入的索引并不能立马被查询到。这里先介绍几个概念

**分片(shard)**

即一个Lucene索引，一个ES索引可以由多个分片组成。分片是ES管理的最小单位。

**分段(segment)**

一个分片由多个分段组成，一个分段对应一个倒排索引。分段是查询管理的最小单位。

**内存索引缓冲区**

新添加的索引并非马上写入磁盘，而是先写入内存，满足一定条件后再写入磁盘，这是为了减少刷入磁盘的次数，减少磁盘IO，提升性能

**translog(事务日志)**

用于在索引从缓冲区刷入磁盘前保存这期间提交的变化。translog 提供所有还没有被刷到磁盘的操作的一个持久化纪录。它会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放 translog 中所有在最后一次提交后发生的变更操作。类似MySQL的redo log

tranlog的另一个作用是提供实时的CRUD。在对段进行检查前，先检查CRUD，意味着它总是能够获取到最新的信息。

**底层原理**

正常查询时，一个分片中由若干个打开的分段提供查询。

新建索引时，会先将索引写入内存缓冲区，等到达到一定条件时再刷入磁盘；每次刷入磁盘的内容都会创建为一个新的分段；为了保证两次刷入磁盘间隔产生的数据丢失，会将这期间的变化存入translog；每次内存索引缓冲区刷入磁盘时，translog就会被截断，截掉已经持久化的提交。持久化间隔默认1s。

而由于每次持久化产生新的分段，过多分段会浪费资源，因此会有分段合并的情况。

## 连问

### 为什么搜索是近实时的。而CRUD的实时的

搜索会先写入缓冲区，再刷入磁盘，这期间写入的索引是不会默认打开以供查询的。除非显式refresh。因此说是近实时的。

CRUD除了从持久化的分段查询，它还从translog查询最新的修改，因此是实时的。

### ES如何保证更新在断电时也不丢失数据？

translog，但默认的设置translog本身5s fsync一次，还是由丢失的风险。可设置为每次提交都fsync，保持绝对安全。

### 为什么删除文档不会立即释放空间？

分段是不可变的，因此删除文档并不能将对应分段删除，相应的只是记录哪些文档被删除了。实际查询中还是会搜索整个分段的内容，然后再提出被标记删除的文档。而释放空间的时机是段的合并。合并时由于会创建新的分段替代旧有分段，旧分段会被删除，此时文档就可以真正被删除了。

### refresh、flush、optimize API都做了什么，什么时候使用？

refresh - 将索引缓冲区中的索引作为segment打开，加入被查询的行列。即使得写入的数据马上可查询。

flush - 将索引缓冲区中的内容写入磁盘，截断translog。

optimize - 强制将分片中的分段数量减少到预先设置的数量。即强制分段合并。

### translog有多安全？

- 写入translog是同步的，即只有在主副分片的translog写入完成后请求才算完成。
- translog也有缓存，先写入缓存，再fsync到磁盘，默认fsync的间隔是5s。可配置
- `"index.translog.durability": "request"`这个可选设置使得每次有写请求时都会马上fsync到磁盘。

### ES重启时如何通过translog恢复数据

commit point。通过比较磁盘中最新的commit point和translog中的commit point，将translog中更新的部分写入磁盘，即恢复了数据。

## Lucene是什么？

简单来说，lucene 就是一个 jar 包，里面包含了封装好的各种建立倒排索引的算法代码。我们用 Java 开发的时候，引入 lucene jar，然后基于 lucene 的 api 去开发就可以了。

通过 lucene，我们可以将已有的数据建立索引，lucene 会在本地磁盘上面，给我们组织索引的数据结构。

Lucene存储是按段(segment)的，每一段本身就是一个倒排索引，

## 倒排索引是什么？

一般文档的组织形式是由id指向一个文档，而倒排索引存储的是文档的分词结果指向文档ID的映射关系。这使得从文档内容查询文档速度变得非常快。而且由于倒排索引存储的分词后的词，因此穷尽了也不会有很多，因为常用英文单词也就数万到数十万的级别；汉语词汇也就数万到数十万的级别；对于索引来说，都是毛毛雨。

## ES的路由指的是什么？路由的算法是什么？

路由指的是索引和查询时，将某个文档指向到某个确定的分片（一个索引可以由多个分片，确定该文档被分配到哪个分片的过程可称为路由）。

算法`shard = hash(routing) % number_of_primary_shards`

routing默认是文档ID。也可以是自定义的值

自定义routing值时，相当于手动设置分片亲和性：将一类文档路由到同一个分片，提升查询速度。

### 为什么在创建索引时指定了分片的数量之后就不能变

由ES的路由算法决定的，路由算法是hash值对分片取余。如果分片数量变了，那么之前的索引将全部错位，发生混乱。

# 关键知识点

## Lucene的倒排索引是不可变的

只有新建和删除，没有更新一说。一个segment就是一个倒排索引，段合并就创建了新的倒排索引。

# 疑问

- ES这类搜索引擎和百度谷歌一类搜索引擎的异同？
- 我们目前系统中的高亮是如何实现的？
- Solr和ES区别？不要完全看网上的对比，他们是带有有色眼镜的，可以参考《Solr实战》
- 什么时候应该使用NoSQL数据库，什么时候应该使用SQL数据库？

